{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this competition a significant delta between local CV and LB scores has been reported in some cases (https://www.kaggle.com/c/trends-assessment-prediction/discussion/153256). We have many features to work with... maybe too many. Reducing variance would seem to be a good thing here and I wanted to investigate the BaggingRegressor for that. The idea is to use the BaggingRegressor to build multiple models, each considering only a fraction of the features, then combine their outputs. From the scikit-learn docs:\n",
    "\n",
    "\"A Bagging regressor is an ensemble meta-estimator that fits base regressors each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\"\n",
    "\n",
    "Ridge regression is known to work well on this dataset, so is used as the base regressor here. The use of the BaggingRegressor is considered as part of a high-performing ensemble, combining SVM and Ridge regression.\n",
    "\n",
    "This notebook is heavily based on @aerdem4's excellent SVM notebook and @tunguz's notebook that adds Ridge regression. Those original notebooks can be found here:\n",
    "https://www.kaggle.com/aerdem4/rapids-svm-on-trends-neuroimaging\n",
    "https://www.kaggle.com/tunguz/rapids-ensemble-for-trends-neuroimaging/\n",
    "\n",
    "## Results\n",
    "\n",
    "After doing an offline sweep of blending weights, the final weights show that for the best local CV, the BaggingRegressor was hardly used for the \"age\" target. However, the BaggingRegressor provided more benefits for the domain variables. In particular for \"domain1_var2\" and \"domain2_var2\" the BaggingRegressor almost completely replaces the basic Ridge regression method.\n",
    "\n",
    "In terms of local CV, the result is almost identical to Bojan's notebook referenced above. On the leaderboard, adding the BaggingRegressor into the ensemble scores 0.1593, an improvement over Bojan's 0.1595. So the local CV to LB delta is successfully reduced, albeit by a little.\n",
    "\n",
    "I find it particularly interesting that only considering small subsets of the features, the BaggingRegressor is competitive for the domain variables but not at all for age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Install Rapids for faster SVM on GPUs\n",
    "\n",
    "import sys\n",
    "!cp ../input/rapids/rapids.0.13.0 /opt/conda/envs/rapids.tar.gz\n",
    "!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.6/site-packages\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.6\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n",
    "!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import warnings\n",
    "from cuml.neighbors import KNeighborsRegressor\n",
    "from cuml import SVR\n",
    "from cuml.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "def metric(y_true, y_pred):\n",
    "    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.6/site-packages/fsspec/implementations/local.py:33: FutureWarning: The default value of auto_mkdir=True has been deprecated and will be changed to auto_mkdir=False by default in a future release.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "fnc_df = cudf.read_csv(\"../input/trends-assessment-prediction/fnc.csv\")\n",
    "loading_df = cudf.read_csv(\"../input/trends-assessment-prediction/loading.csv\")\n",
    "\n",
    "fnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\n",
    "df = fnc_df.merge(loading_df, on=\"Id\")\n",
    "\n",
    "\n",
    "labels_df = cudf.read_csv(\"../input/trends-assessment-prediction/train_scores.csv\")\n",
    "labels_df[\"is_train\"] = True\n",
    "\n",
    "df = df.merge(labels_df, on=\"Id\", how=\"left\")\n",
    "\n",
    "test_df = df[df[\"is_train\"] != True].copy()\n",
    "df = df[df[\"is_train\"] == True].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving less importance to FNC features since they are easier to overfit due to high dimensionality.\n",
    "FNC_SCALE = 1/600\n",
    "\n",
    "df[fnc_features] *= FNC_SCALE\n",
    "test_df[fnc_features] *= FNC_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "dffit = scaler.fit_transform(df[fnc_features].to_pandas())\n",
    "testfit = scaler.fit_transform(test_df[fnc_features].to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.DataFrame(dffit)\n",
    "dfn = cudf.DataFrame(dfn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testn = pd.DataFrame(testfit)\n",
    "testn = cudf.DataFrame(testn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1368</th>\n",
       "      <th>1369</th>\n",
       "      <th>1370</th>\n",
       "      <th>1371</th>\n",
       "      <th>1372</th>\n",
       "      <th>1373</th>\n",
       "      <th>1374</th>\n",
       "      <th>1375</th>\n",
       "      <th>1376</th>\n",
       "      <th>1377</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.115210</td>\n",
       "      <td>-0.564800</td>\n",
       "      <td>-0.346825</td>\n",
       "      <td>-0.652229</td>\n",
       "      <td>0.309619</td>\n",
       "      <td>0.396194</td>\n",
       "      <td>0.321085</td>\n",
       "      <td>0.274943</td>\n",
       "      <td>0.408415</td>\n",
       "      <td>0.153251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.558840</td>\n",
       "      <td>1.121838</td>\n",
       "      <td>0.320730</td>\n",
       "      <td>0.400996</td>\n",
       "      <td>-0.840185</td>\n",
       "      <td>-0.738112</td>\n",
       "      <td>-0.441600</td>\n",
       "      <td>-0.072529</td>\n",
       "      <td>0.083354</td>\n",
       "      <td>0.041877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.860023</td>\n",
       "      <td>-0.806715</td>\n",
       "      <td>-1.990393</td>\n",
       "      <td>-0.283466</td>\n",
       "      <td>-0.125322</td>\n",
       "      <td>-0.171817</td>\n",
       "      <td>0.069740</td>\n",
       "      <td>0.702356</td>\n",
       "      <td>1.074101</td>\n",
       "      <td>0.964191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235684</td>\n",
       "      <td>-1.091728</td>\n",
       "      <td>-0.490821</td>\n",
       "      <td>0.054676</td>\n",
       "      <td>-0.002598</td>\n",
       "      <td>0.223839</td>\n",
       "      <td>-0.204375</td>\n",
       "      <td>-0.606344</td>\n",
       "      <td>-0.087591</td>\n",
       "      <td>-0.095824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.216902</td>\n",
       "      <td>0.450364</td>\n",
       "      <td>0.410574</td>\n",
       "      <td>0.159720</td>\n",
       "      <td>0.297364</td>\n",
       "      <td>0.384684</td>\n",
       "      <td>-0.331900</td>\n",
       "      <td>-0.214646</td>\n",
       "      <td>-0.072133</td>\n",
       "      <td>-0.304650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076588</td>\n",
       "      <td>0.707393</td>\n",
       "      <td>-1.650938</td>\n",
       "      <td>1.291996</td>\n",
       "      <td>-0.453432</td>\n",
       "      <td>0.447590</td>\n",
       "      <td>0.072392</td>\n",
       "      <td>-0.305047</td>\n",
       "      <td>0.420707</td>\n",
       "      <td>-0.337515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162220</td>\n",
       "      <td>0.551207</td>\n",
       "      <td>-0.867616</td>\n",
       "      <td>-0.325059</td>\n",
       "      <td>0.270928</td>\n",
       "      <td>0.901800</td>\n",
       "      <td>0.141748</td>\n",
       "      <td>0.252126</td>\n",
       "      <td>-0.235481</td>\n",
       "      <td>0.590514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565377</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>-0.072337</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>-0.078050</td>\n",
       "      <td>-1.188077</td>\n",
       "      <td>-1.155756</td>\n",
       "      <td>-0.345728</td>\n",
       "      <td>-1.446115</td>\n",
       "      <td>0.019472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.885463</td>\n",
       "      <td>-1.594216</td>\n",
       "      <td>-2.094349</td>\n",
       "      <td>-1.541049</td>\n",
       "      <td>-0.869234</td>\n",
       "      <td>-0.586263</td>\n",
       "      <td>-0.305070</td>\n",
       "      <td>-0.061576</td>\n",
       "      <td>0.340020</td>\n",
       "      <td>-0.098498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995042</td>\n",
       "      <td>-0.845467</td>\n",
       "      <td>-1.149858</td>\n",
       "      <td>-1.172092</td>\n",
       "      <td>-0.229493</td>\n",
       "      <td>-0.191816</td>\n",
       "      <td>-0.331939</td>\n",
       "      <td>-0.017552</td>\n",
       "      <td>-0.727600</td>\n",
       "      <td>0.223092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>-0.252459</td>\n",
       "      <td>0.089144</td>\n",
       "      <td>0.466345</td>\n",
       "      <td>-1.239722</td>\n",
       "      <td>0.688019</td>\n",
       "      <td>0.493994</td>\n",
       "      <td>0.229923</td>\n",
       "      <td>-0.151674</td>\n",
       "      <td>-0.062975</td>\n",
       "      <td>0.332829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267457</td>\n",
       "      <td>0.477674</td>\n",
       "      <td>-1.392595</td>\n",
       "      <td>1.068518</td>\n",
       "      <td>-0.062064</td>\n",
       "      <td>-0.349212</td>\n",
       "      <td>-0.613537</td>\n",
       "      <td>-0.324463</td>\n",
       "      <td>0.226153</td>\n",
       "      <td>-0.373786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>-0.129314</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>-0.364198</td>\n",
       "      <td>0.036579</td>\n",
       "      <td>0.311234</td>\n",
       "      <td>0.060626</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>-0.281670</td>\n",
       "      <td>-0.388019</td>\n",
       "      <td>-0.230108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919615</td>\n",
       "      <td>0.183870</td>\n",
       "      <td>1.123991</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>-1.473121</td>\n",
       "      <td>-1.160874</td>\n",
       "      <td>-1.449639</td>\n",
       "      <td>0.070451</td>\n",
       "      <td>-0.107701</td>\n",
       "      <td>0.350745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>-1.659498</td>\n",
       "      <td>-1.032821</td>\n",
       "      <td>-0.748854</td>\n",
       "      <td>-1.728834</td>\n",
       "      <td>0.901963</td>\n",
       "      <td>0.623707</td>\n",
       "      <td>0.768582</td>\n",
       "      <td>0.753376</td>\n",
       "      <td>-0.315562</td>\n",
       "      <td>0.458227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541791</td>\n",
       "      <td>-0.097608</td>\n",
       "      <td>0.581478</td>\n",
       "      <td>0.208402</td>\n",
       "      <td>0.491851</td>\n",
       "      <td>0.315748</td>\n",
       "      <td>-0.111102</td>\n",
       "      <td>0.354104</td>\n",
       "      <td>-0.542409</td>\n",
       "      <td>0.009353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>-0.326964</td>\n",
       "      <td>-0.742584</td>\n",
       "      <td>-0.310322</td>\n",
       "      <td>-1.211476</td>\n",
       "      <td>0.288336</td>\n",
       "      <td>-0.285977</td>\n",
       "      <td>0.935511</td>\n",
       "      <td>-0.138513</td>\n",
       "      <td>0.958717</td>\n",
       "      <td>-0.293915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867476</td>\n",
       "      <td>-0.721944</td>\n",
       "      <td>0.608446</td>\n",
       "      <td>-0.007352</td>\n",
       "      <td>0.323922</td>\n",
       "      <td>-0.363531</td>\n",
       "      <td>0.057072</td>\n",
       "      <td>-0.392303</td>\n",
       "      <td>0.698606</td>\n",
       "      <td>-0.586296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>-0.178834</td>\n",
       "      <td>0.304941</td>\n",
       "      <td>0.113601</td>\n",
       "      <td>-0.740899</td>\n",
       "      <td>1.097430</td>\n",
       "      <td>0.745079</td>\n",
       "      <td>0.885890</td>\n",
       "      <td>0.992494</td>\n",
       "      <td>0.499860</td>\n",
       "      <td>0.739006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263728</td>\n",
       "      <td>0.116201</td>\n",
       "      <td>-0.270288</td>\n",
       "      <td>0.742062</td>\n",
       "      <td>-1.245524</td>\n",
       "      <td>-0.190429</td>\n",
       "      <td>-0.647193</td>\n",
       "      <td>-0.223585</td>\n",
       "      <td>-0.531519</td>\n",
       "      <td>-0.467855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows × 1378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0    -0.115210 -0.564800 -0.346825 -0.652229  0.309619  0.396194  0.321085   \n",
       "1    -0.860023 -0.806715 -1.990393 -0.283466 -0.125322 -0.171817  0.069740   \n",
       "2    -0.216902  0.450364  0.410574  0.159720  0.297364  0.384684 -0.331900   \n",
       "3     0.162220  0.551207 -0.867616 -0.325059  0.270928  0.901800  0.141748   \n",
       "4    -0.885463 -1.594216 -2.094349 -1.541049 -0.869234 -0.586263 -0.305070   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5872 -0.252459  0.089144  0.466345 -1.239722  0.688019  0.493994  0.229923   \n",
       "5873 -0.129314 -0.003485 -0.364198  0.036579  0.311234  0.060626  0.000601   \n",
       "5874 -1.659498 -1.032821 -0.748854 -1.728834  0.901963  0.623707  0.768582   \n",
       "5875 -0.326964 -0.742584 -0.310322 -1.211476  0.288336 -0.285977  0.935511   \n",
       "5876 -0.178834  0.304941  0.113601 -0.740899  1.097430  0.745079  0.885890   \n",
       "\n",
       "          7         8         9     ...      1368      1369      1370  \\\n",
       "0     0.274943  0.408415  0.153251  ... -0.558840  1.121838  0.320730   \n",
       "1     0.702356  1.074101  0.964191  ...  0.235684 -1.091728 -0.490821   \n",
       "2    -0.214646 -0.072133 -0.304650  ...  0.076588  0.707393 -1.650938   \n",
       "3     0.252126 -0.235481  0.590514  ... -0.565377  0.416175 -0.072337   \n",
       "4    -0.061576  0.340020 -0.098498  ... -0.995042 -0.845467 -1.149858   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5872 -0.151674 -0.062975  0.332829  ... -0.267457  0.477674 -1.392595   \n",
       "5873 -0.281670 -0.388019 -0.230108  ... -0.919615  0.183870  1.123991   \n",
       "5874  0.753376 -0.315562  0.458227  ...  0.541791 -0.097608  0.581478   \n",
       "5875 -0.138513  0.958717 -0.293915  ...  0.867476 -0.721944  0.608446   \n",
       "5876  0.992494  0.499860  0.739006  ...  0.263728  0.116201 -0.270288   \n",
       "\n",
       "          1371      1372      1373      1374      1375      1376      1377  \n",
       "0     0.400996 -0.840185 -0.738112 -0.441600 -0.072529  0.083354  0.041877  \n",
       "1     0.054676 -0.002598  0.223839 -0.204375 -0.606344 -0.087591 -0.095824  \n",
       "2     1.291996 -0.453432  0.447590  0.072392 -0.305047  0.420707 -0.337515  \n",
       "3     0.397661 -0.078050 -1.188077 -1.155756 -0.345728 -1.446115  0.019472  \n",
       "4    -1.172092 -0.229493 -0.191816 -0.331939 -0.017552 -0.727600  0.223092  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5872  1.068518 -0.062064 -0.349212 -0.613537 -0.324463  0.226153 -0.373786  \n",
       "5873  0.739125 -1.473121 -1.160874 -1.449639  0.070451 -0.107701  0.350745  \n",
       "5874  0.208402  0.491851  0.315748 -0.111102  0.354104 -0.542409  0.009353  \n",
       "5875 -0.007352  0.323922 -0.363531  0.057072 -0.392303  0.698606 -0.586296  \n",
       "5876  0.742062 -1.245524 -0.190429 -0.647193 -0.223585 -0.531519 -0.467855  \n",
       "\n",
       "[5877 rows x 1378 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[fnc_features] = dfn\n",
    "test_df[fnc_features] = testn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SCN(53)_vs_SCN(69)</th>\n",
       "      <th>SCN(98)_vs_SCN(69)</th>\n",
       "      <th>SCN(99)_vs_SCN(69)</th>\n",
       "      <th>SCN(45)_vs_SCN(69)</th>\n",
       "      <th>ADN(21)_vs_SCN(69)</th>\n",
       "      <th>ADN(56)_vs_SCN(69)</th>\n",
       "      <th>SMN(3)_vs_SCN(69)</th>\n",
       "      <th>SMN(9)_vs_SCN(69)</th>\n",
       "      <th>SMN(2)_vs_SCN(69)</th>\n",
       "      <th>...</th>\n",
       "      <th>IC_30</th>\n",
       "      <th>IC_22</th>\n",
       "      <th>IC_29</th>\n",
       "      <th>IC_14</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18240</td>\n",
       "      <td>-0.115210</td>\n",
       "      <td>-0.564800</td>\n",
       "      <td>-0.346825</td>\n",
       "      <td>-0.652229</td>\n",
       "      <td>0.309619</td>\n",
       "      <td>0.396194</td>\n",
       "      <td>0.321085</td>\n",
       "      <td>0.274943</td>\n",
       "      <td>0.408415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>50.427747</td>\n",
       "      <td>29.90305385</td>\n",
       "      <td>61.05115855</td>\n",
       "      <td>50.06049358</td>\n",
       "      <td>61.24677336</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13820</td>\n",
       "      <td>-0.860023</td>\n",
       "      <td>-0.806715</td>\n",
       "      <td>-1.990393</td>\n",
       "      <td>-0.283466</td>\n",
       "      <td>-0.125322</td>\n",
       "      <td>-0.171817</td>\n",
       "      <td>0.069740</td>\n",
       "      <td>0.702356</td>\n",
       "      <td>1.074101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>-0.011408</td>\n",
       "      <td>0.023409</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>55.456978</td>\n",
       "      <td>49.38457261</td>\n",
       "      <td>60.29300963</td>\n",
       "      <td>60.54383047</td>\n",
       "      <td>37.34441091</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13809</td>\n",
       "      <td>-0.216902</td>\n",
       "      <td>0.450364</td>\n",
       "      <td>0.410574</td>\n",
       "      <td>0.159720</td>\n",
       "      <td>0.297364</td>\n",
       "      <td>0.384684</td>\n",
       "      <td>-0.331900</td>\n",
       "      <td>-0.214646</td>\n",
       "      <td>-0.072133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.014255</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.020297</td>\n",
       "      <td>36.961174</td>\n",
       "      <td>43.71688625</td>\n",
       "      <td>58.09714123</td>\n",
       "      <td>42.14923716</td>\n",
       "      <td>44.51487978</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13825</td>\n",
       "      <td>0.162220</td>\n",
       "      <td>0.551207</td>\n",
       "      <td>-0.867616</td>\n",
       "      <td>-0.325059</td>\n",
       "      <td>0.270928</td>\n",
       "      <td>0.901800</td>\n",
       "      <td>0.141748</td>\n",
       "      <td>0.252126</td>\n",
       "      <td>-0.235481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001308</td>\n",
       "      <td>-0.012427</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>47.470203</td>\n",
       "      <td>57.40391654</td>\n",
       "      <td>71.73026129</td>\n",
       "      <td>46.26066048</td>\n",
       "      <td>43.9657463</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13810</td>\n",
       "      <td>-0.885463</td>\n",
       "      <td>-1.594216</td>\n",
       "      <td>-2.094349</td>\n",
       "      <td>-1.541049</td>\n",
       "      <td>-0.869234</td>\n",
       "      <td>-0.586263</td>\n",
       "      <td>-0.305070</td>\n",
       "      <td>-0.061576</td>\n",
       "      <td>0.340020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>-0.008199</td>\n",
       "      <td>0.020756</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>48.948756</td>\n",
       "      <td>50.30134784</td>\n",
       "      <td>63.01577288</td>\n",
       "      <td>44.89238229</td>\n",
       "      <td>56.51086817</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>16299</td>\n",
       "      <td>-0.252459</td>\n",
       "      <td>0.089144</td>\n",
       "      <td>0.466345</td>\n",
       "      <td>-1.239722</td>\n",
       "      <td>0.688019</td>\n",
       "      <td>0.493994</td>\n",
       "      <td>0.229923</td>\n",
       "      <td>-0.151674</td>\n",
       "      <td>-0.062975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>-0.018767</td>\n",
       "      <td>0.021829</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>64.203107</td>\n",
       "      <td>62.68657086</td>\n",
       "      <td>62.63511667</td>\n",
       "      <td>57.4445276</td>\n",
       "      <td>38.03955027</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11733</th>\n",
       "      <td>16301</td>\n",
       "      <td>-0.129314</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>-0.364198</td>\n",
       "      <td>0.036579</td>\n",
       "      <td>0.311234</td>\n",
       "      <td>0.060626</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>-0.281670</td>\n",
       "      <td>-0.388019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>-0.011617</td>\n",
       "      <td>0.023664</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>41.56829107</td>\n",
       "      <td>68.55638681</td>\n",
       "      <td>34.59675355</td>\n",
       "      <td>37.58509756</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11734</th>\n",
       "      <td>16278</td>\n",
       "      <td>-1.659498</td>\n",
       "      <td>-1.032821</td>\n",
       "      <td>-0.748854</td>\n",
       "      <td>-1.728834</td>\n",
       "      <td>0.901963</td>\n",
       "      <td>0.623707</td>\n",
       "      <td>0.768582</td>\n",
       "      <td>0.753376</td>\n",
       "      <td>-0.315562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>-0.013141</td>\n",
       "      <td>0.019981</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>36.961174</td>\n",
       "      <td>41.84858971</td>\n",
       "      <td>55.78433221</td>\n",
       "      <td>19.69845939</td>\n",
       "      <td>16.32976701</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11735</th>\n",
       "      <td>20136</td>\n",
       "      <td>-0.326964</td>\n",
       "      <td>-0.742584</td>\n",
       "      <td>-0.310322</td>\n",
       "      <td>-1.211476</td>\n",
       "      <td>0.288336</td>\n",
       "      <td>-0.285977</td>\n",
       "      <td>0.935511</td>\n",
       "      <td>-0.138513</td>\n",
       "      <td>0.958717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>-0.007180</td>\n",
       "      <td>0.034187</td>\n",
       "      <td>0.018442</td>\n",
       "      <td>28.442742</td>\n",
       "      <td>55.73784501</td>\n",
       "      <td>37.3279806</td>\n",
       "      <td>36.88775907</td>\n",
       "      <td>48.46559788</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11736</th>\n",
       "      <td>16292</td>\n",
       "      <td>-0.178834</td>\n",
       "      <td>0.304941</td>\n",
       "      <td>0.113601</td>\n",
       "      <td>-0.740899</td>\n",
       "      <td>1.097430</td>\n",
       "      <td>0.745079</td>\n",
       "      <td>0.885890</td>\n",
       "      <td>0.992494</td>\n",
       "      <td>0.499860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.019078</td>\n",
       "      <td>0.023369</td>\n",
       "      <td>0.026916</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>61.65360214</td>\n",
       "      <td>74.81263067</td>\n",
       "      <td>59.81302249</td>\n",
       "      <td>63.04601334</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5877 rows × 1411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  SCN(53)_vs_SCN(69)  SCN(98)_vs_SCN(69)  SCN(99)_vs_SCN(69)  \\\n",
       "0      18240           -0.115210           -0.564800           -0.346825   \n",
       "1      13820           -0.860023           -0.806715           -1.990393   \n",
       "2      13809           -0.216902            0.450364            0.410574   \n",
       "3      13825            0.162220            0.551207           -0.867616   \n",
       "4      13810           -0.885463           -1.594216           -2.094349   \n",
       "...      ...                 ...                 ...                 ...   \n",
       "11732  16299           -0.252459            0.089144            0.466345   \n",
       "11733  16301           -0.129314           -0.003485           -0.364198   \n",
       "11734  16278           -1.659498           -1.032821           -0.748854   \n",
       "11735  20136           -0.326964           -0.742584           -0.310322   \n",
       "11736  16292           -0.178834            0.304941            0.113601   \n",
       "\n",
       "       SCN(45)_vs_SCN(69)  ADN(21)_vs_SCN(69)  ADN(56)_vs_SCN(69)  \\\n",
       "0               -0.652229            0.309619            0.396194   \n",
       "1               -0.283466           -0.125322           -0.171817   \n",
       "2                0.159720            0.297364            0.384684   \n",
       "3               -0.325059            0.270928            0.901800   \n",
       "4               -1.541049           -0.869234           -0.586263   \n",
       "...                   ...                 ...                 ...   \n",
       "11732           -1.239722            0.688019            0.493994   \n",
       "11733            0.036579            0.311234            0.060626   \n",
       "11734           -1.728834            0.901963            0.623707   \n",
       "11735           -1.211476            0.288336           -0.285977   \n",
       "11736           -0.740899            1.097430            0.745079   \n",
       "\n",
       "       SMN(3)_vs_SCN(69)  SMN(9)_vs_SCN(69)  SMN(2)_vs_SCN(69)  ...     IC_30  \\\n",
       "0               0.321085           0.274943           0.408415  ...  0.003238   \n",
       "1               0.069740           0.702356           1.074101  ...  0.001940   \n",
       "2              -0.331900          -0.214646          -0.072133  ... -0.000252   \n",
       "3               0.141748           0.252126          -0.235481  ... -0.001308   \n",
       "4              -0.305070          -0.061576           0.340020  ...  0.000825   \n",
       "...                  ...                ...                ...  ...       ...   \n",
       "11732           0.229923          -0.151674          -0.062975  ...  0.001949   \n",
       "11733           0.000601          -0.281670          -0.388019  ...  0.004872   \n",
       "11734           0.768582           0.753376          -0.315562  ... -0.000530   \n",
       "11735           0.935511          -0.138513           0.958717  ...  0.003586   \n",
       "11736           0.885890           0.992494           0.499860  ...  0.002100   \n",
       "\n",
       "          IC_22     IC_29     IC_14        age  domain1_var1  domain1_var2  \\\n",
       "0     -0.006451  0.030605  0.016639  50.427747   29.90305385   61.05115855   \n",
       "1     -0.011408  0.023409  0.013241  55.456978   49.38457261   60.29300963   \n",
       "2     -0.014255  0.030720  0.020297  36.961174   43.71688625   58.09714123   \n",
       "3     -0.012427  0.021317  0.011156  47.470203   57.40391654   71.73026129   \n",
       "4     -0.008199  0.020756  0.014812  48.948756   50.30134784   63.01577288   \n",
       "...         ...       ...       ...        ...           ...           ...   \n",
       "11732 -0.018767  0.021829  0.016573  64.203107   62.68657086   62.63511667   \n",
       "11733 -0.011617  0.023664  0.010137  57.436077   41.56829107   68.55638681   \n",
       "11734 -0.013141  0.019981  0.012371  36.961174   41.84858971   55.78433221   \n",
       "11735 -0.007180  0.034187  0.018442  28.442742   55.73784501    37.3279806   \n",
       "11736 -0.019078  0.023369  0.026916  66.532630   61.65360214   74.81263067   \n",
       "\n",
       "      domain2_var1 domain2_var2 is_train  \n",
       "0      50.06049358  61.24677336     True  \n",
       "1      60.54383047  37.34441091     True  \n",
       "2      42.14923716  44.51487978     True  \n",
       "3      46.26066048   43.9657463     True  \n",
       "4      44.89238229  56.51086817     True  \n",
       "...            ...          ...      ...  \n",
       "11732   57.4445276  38.03955027     True  \n",
       "11733  34.59675355  37.58509756     True  \n",
       "11734  19.69845939  16.32976701     True  \n",
       "11735  36.88775907  48.46559788     True  \n",
       "11736  59.81302249  63.04601334     True  \n",
       "\n",
       "[5877 rows x 1411 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# BaggingRegressor + RAPIDS Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For age:\n",
      "SVR: 0.177918\n",
      "Ridge: 0.161465\n",
      "BaggingRegressor: 0.152276\n",
      "Ensemble: 0.15406\n",
      "\n",
      "For domain1_var1:\n",
      "SVR: 0.15621\n",
      "Ridge: 0.177086\n",
      "BaggingRegressor: 0.154881\n",
      "Ensemble: 0.154691\n",
      "\n",
      "For domain1_var2:\n",
      "SVR: 0.153625\n",
      "Ridge: 0.178628\n",
      "BaggingRegressor: 0.155128\n",
      "Ensemble: 0.153234\n",
      "\n",
      "For domain2_var1:\n",
      "SVR: 0.184502\n",
      "Ridge: 0.210831\n",
      "BaggingRegressor: 0.185102\n",
      "Ensemble: 0.183948\n",
      "\n",
      "For domain2_var2:\n",
      "SVR: 0.179985\n",
      "Ridge: 0.206575\n",
      "BaggingRegressor: 0.179392\n",
      "Ensemble: 0.178435\n",
      "\n",
      "Overall score: 0.163522\n",
      "CPU times: user 8min 39s, sys: 26.4 s, total: 9min 5s\n",
      "Wall time: 9min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# To suppress the \"Expected column ('F') major order, but got the opposite.\" warnings from cudf. It should be fixed properly,\n",
    "# although as the only impact is additional memory usage, I'll supress it for now.\n",
    "warnings.filterwarnings(\"ignore\", message=\"Expected column\")\n",
    "\n",
    "# Take a copy of the main dataframe, to report on per-target scores for each model.\n",
    "# TODO Copy less to make this more efficient.\n",
    "df_model1 = df.copy()\n",
    "df_model2 = df.copy()\n",
    "df_model3 = df.copy()\n",
    "\n",
    "NUM_FOLDS = 7\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n",
    "\n",
    "features = loading_features + fnc_features\n",
    "\n",
    "# Blending weights between the three models are specified separately for the 5 targets. \n",
    "#                                 SVR,  Ridge, BaggingRegressor\n",
    "blend_weights = {\"age\":          [0.4,  0.55,  0.05],\n",
    "                 \"domain1_var1\": [0.55, 0.15,  0.3],\n",
    "                 \"domain1_var2\": [0.45, 0.0,   0.55],\n",
    "                 \"domain2_var1\": [0.55, 0.15,  0.3],\n",
    "                 \"domain2_var2\": [0.5,  0.05,  0.45]}\n",
    "\n",
    "overall_score = 0\n",
    "for target, c, w in [(\"age\", 60, 0.3), (\"domain1_var1\", 12, 0.175), (\"domain1_var2\", 8, 0.175), (\"domain2_var1\", 9, 0.175), (\"domain2_var2\", 12, 0.175)]:    \n",
    "    y_oof = np.zeros(df.shape[0])\n",
    "    y_oof_model_1 = np.zeros(df.shape[0])\n",
    "    y_oof_model_2 = np.zeros(df.shape[0])\n",
    "    y_oof_model_3 = np.zeros(df.shape[0])\n",
    "    y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n",
    "    \n",
    "    for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n",
    "        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n",
    "        train_df = train_df[train_df[target].notnull()]\n",
    "\n",
    "        model_1 = SVR(C=c, cache_size=3000.0)\n",
    "        model_1.fit(train_df[features].values, train_df[target].values)\n",
    "        model_2 = Ridge(alpha = 0.0001)\n",
    "        model_2.fit(train_df[features].values, train_df[target].values)\n",
    "        \n",
    "        ### The BaggingRegressor, using the Ridge regression method as a base, is added here. The BaggingRegressor\n",
    "        # is from sklearn, not RAPIDS, so dataframes need converting to Pandas.\n",
    "        model_3 = BaggingRegressor(Ridge(alpha = 0.0001), n_estimators=30, random_state=42, max_samples=0.3, max_features=0.3)\n",
    "        model_3.fit(train_df.to_pandas()[features].values, train_df.to_pandas()[target].values)\n",
    "\n",
    "        val_pred_1 = model_1.predict(val_df[features])\n",
    "        val_pred_2 = model_2.predict(val_df[features])\n",
    "        val_pred_3 = model_3.predict(val_df.to_pandas()[features])\n",
    "        val_pred_3 = cudf.from_pandas(pd.Series(val_pred_3))\n",
    "        \n",
    "        test_pred_1 = model_1.predict(test_df[features])\n",
    "        test_pred_2 = model_2.predict(test_df[features])\n",
    "        test_pred_3 = model_3.predict(test_df.to_pandas()[features])\n",
    "        test_pred_3 = cudf.from_pandas(pd.Series(test_pred_3))\n",
    "        \n",
    "        val_pred = blend_weights[target][0]*val_pred_1+blend_weights[target][1]*val_pred_2+blend_weights[target][2]*val_pred_3\n",
    "        val_pred = cp.asnumpy(val_pred.values.flatten())\n",
    "        \n",
    "        test_pred = blend_weights[target][0]*test_pred_1+blend_weights[target][1]*test_pred_2+blend_weights[target][2]*test_pred_3\n",
    "        test_pred = cp.asnumpy(test_pred.values.flatten())\n",
    "        \n",
    "        y_oof[val_ind] = val_pred\n",
    "        y_oof_model_1[val_ind] = val_pred_1\n",
    "        y_oof_model_2[val_ind] = val_pred_2\n",
    "        y_oof_model_3[val_ind] = val_pred_3\n",
    "        y_test[:, f] = test_pred\n",
    "        \n",
    "    df[\"pred_{}\".format(target)] = y_oof\n",
    "    df_model1[\"pred_{}\".format(target)] = y_oof_model_1\n",
    "    df_model2[\"pred_{}\".format(target)] = y_oof_model_2\n",
    "    df_model3[\"pred_{}\".format(target)] = y_oof_model_3\n",
    "    test_df[target] = y_test.mean(axis=1)\n",
    "    \n",
    "    score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values)\n",
    "    overall_score += w*score\n",
    "    \n",
    "    score_model1 = metric(df_model1[df_model1[target].notnull()][target].values, df_model1[df_model1[target].notnull()][\"pred_{}\".format(target)].values)\n",
    "    score_model2 = metric(df_model2[df_model2[target].notnull()][target].values, df_model2[df_model1[target].notnull()][\"pred_{}\".format(target)].values)\n",
    "    score_model3 = metric(df_model3[df_model3[target].notnull()][target].values, df_model3[df_model1[target].notnull()][\"pred_{}\".format(target)].values)\n",
    "\n",
    "    print(f\"For {target}:\")\n",
    "    print(\"SVR:\", np.round(score_model1, 6))\n",
    "    print(\"Ridge:\", np.round(score_model2, 6))\n",
    "    print(\"BaggingRegressor:\", np.round(score_model3, 6))\n",
    "    print(\"Ensemble:\", np.round(score, 6))\n",
    "    print()\n",
    "    \n",
    "print(\"Overall score:\", np.round(overall_score, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>10003_age</td>\n",
       "      <td>67.524744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7463</th>\n",
       "      <td>10003_domain1_var1</td>\n",
       "      <td>52.947820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>10003_domain1_var2</td>\n",
       "      <td>57.650484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19217</th>\n",
       "      <td>10003_domain2_var1</td>\n",
       "      <td>52.470429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25094</th>\n",
       "      <td>10003_domain2_var2</td>\n",
       "      <td>56.440817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>10006_age</td>\n",
       "      <td>67.370129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7470</th>\n",
       "      <td>10006_domain1_var1</td>\n",
       "      <td>57.678881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13347</th>\n",
       "      <td>10006_domain1_var2</td>\n",
       "      <td>59.048261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19224</th>\n",
       "      <td>10006_domain2_var1</td>\n",
       "      <td>44.898143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25101</th>\n",
       "      <td>10006_domain2_var2</td>\n",
       "      <td>52.379146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id  Predicted\n",
       "1586            10003_age  67.524744\n",
       "7463   10003_domain1_var1  52.947820\n",
       "13340  10003_domain1_var2  57.650484\n",
       "19217  10003_domain2_var1  52.470429\n",
       "25094  10003_domain2_var2  56.440817\n",
       "1593            10006_age  67.370129\n",
       "7470   10006_domain1_var1  57.678881\n",
       "13347  10006_domain1_var2  59.048261\n",
       "19224  10006_domain2_var1  44.898143\n",
       "25101  10006_domain2_var2  52.379146"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = cudf.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\n",
    "sub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n",
    "\n",
    "sub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\n",
    "assert sub_df.shape[0] == test_df.shape[0]*5\n",
    "sub_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission_rapids_ensemble_with_baggingregressor.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
